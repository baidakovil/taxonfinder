# Обработка и алгоритмы

Подробное описание экстракторов, нормализации и алгоритмов разрешения таксонов.
Общая архитектура и пайплайн описаны в [projectdescription.md](../projectdescription.md).

## Газеттер

Газеттер — основной экстрактор, обеспечивающий предсказуемый recall для известных названий.
Данные загружаются из iNaturalist API и хранятся в локальной SQLite-базе
(`data/gazetteer.db`).

### Требуемые данные

Для каждого таксона в газеттере хранятся:
- **taxon_id** — идентификатор таксона в iNaturalist.
- **taxon_name** — научное (латинское) название.
- **taxon_rank** — таксономический ранг (species, genus, family и т.д.).
- **ancestry** — цепочка предковых таксонов для будущей фильтрации по таксономическому
  дереву.
- **Все common names** для настроенных локалей (как минимум `ru` и `en`):
  название, флаг `is_preferred`, `locale`, `lexicon`.

Источник данных: поля `name`, `rank`, `ancestry`, `preferred_common_name`, `names` из
объектов Taxon, получаемых через iNaturalist API.

### Схема SQLite

```sql
CREATE TABLE schema_version (
    version INTEGER NOT NULL,
    created_at TEXT NOT NULL DEFAULT (datetime('now'))
);

CREATE TABLE taxa (
    taxon_id INTEGER PRIMARY KEY,
    taxon_name TEXT NOT NULL,
    taxon_rank TEXT NOT NULL,
    ancestry TEXT
);

CREATE TABLE common_names (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    taxon_id INTEGER NOT NULL REFERENCES taxa(taxon_id),
    name TEXT NOT NULL,
    name_normalized TEXT NOT NULL,
    name_lemmatized TEXT,
    locale TEXT NOT NULL,
    is_preferred BOOLEAN DEFAULT 0,
    lexicon TEXT
);

CREATE INDEX idx_cn_normalized ON common_names(name_normalized);
CREATE INDEX idx_cn_lemmatized ON common_names(name_lemmatized);
CREATE INDEX idx_cn_locale ON common_names(locale);
CREATE INDEX idx_cn_taxon ON common_names(taxon_id);
```

Таблица `schema_version` содержит текущую версию схемы. При запуске приложение проверяет
совместимость и завершается с понятным сообщением об ошибке при несовпадении версии.

### Загрузка в runtime

При старте:
1. Открывает `data/gazetteer.db` (путь из конфигурации, поле `gazetteer_path`).
2. Проверяет `schema_version`.
3. Загружает `name_normalized` и `name_lemmatized` для настроенной локали
   в spaCy `PhraseMatcher`.
4. Хранит в памяти маппинг `name_normalized → list[taxon_id]` для быстрого поиска.

При совпадении PhraseMatcher возвращает span, по которому из маппинга извлекаются
`taxon_id`, а из SQLite — полная информация о таксоне.

### Оценка объёма

Газеттер не загружает все таксоны iNaturalist (их миллионы). Набор ограничивается
критериями загрузчика (контрольный список, place_id, iconic taxa и т.д.). Ориентировочный
размер: 50 000–200 000 common names. PhraseMatcher с таким количеством паттернов
потребляет ~100–500 МБ RAM и инициализируется за несколько секунд.

### Обновление

Газеттер строится отдельной CLI-командой (`taxonfinder build-gazetteer`) и не обновляется
автоматически. Пересборка выполняется вручную при необходимости.

## Regex-детектор латинских биномиалов

Базовый паттерн: `[A-Z][a-z]+ [a-z]+( [a-z]+)?` — ловит латинские биномиалы, но
даёт ложные срабатывания на небиологических латинских фразах, именах собственных
и географических названиях. В русскоязычном тексте проблема смягчена (латиница
выделяется на фоне кириллицы), но фильтрация необходима.

### Эвристические фильтры (применяются последовательно)

1. **Минимальная длина слов:** оба слова биномиала >= 3 символов.
   Отсекает «In vitro», «Ad hoc».
2. **Стоп-лист латинских фраз:** набор небиологических выражений: «Et cetera»,
   «Ad libitum», «In situ», «Ex vivo», «De facto», «Pro rata», «Per se»,
   «Ab initio», «Status quo», «Modus operandi», «Alma mater», «Anno domini».
   Хранится как константа в `extractors/latin.py`, может быть расширен.
3. **Проверка по газеттеру:** если совпадение найдено в `taxa.taxon_name` — кандидат
   подтверждён (confidence повышается до 0.9).
4. **Контекстная эвристика:** если совпадение следует непосредственно за обращением
   (Mr., Dr., Prof., von, van) — вероятно имя человека, кандидат отклоняется.

Порядок:

```
regex match → фильтр длины → стоп-лист → проверка газеттера → контекстная эвристика
            → прошёл все фильтры? → кандидат
```

Кандидаты, прошедшие фильтры, но не найденные в газеттере, всё равно отправляются
в iNaturalist для верификации на Фазе 3.

## LLM

### LLM-экстрактор (Фаза 1)

**Задача:** Найти названия организмов, не пойманные газеттером и regex —
региональные, просторечные, устаревшие названия, отсутствующие в словаре.

**Вход:** Чанк текста (абзац или страница). Размер регулируется параметрами
`chunk_strategy`, `min_chunk_words`, `max_chunk_words` в конфигурации.

**Выход:**

```json
{
  "candidates": [
    {"name": "чёртово дерево", "context": "первые слова предложения..."},
    {"name": "горный баран", "context": "первые слова предложения..."}
  ]
}
```

Если организмов не найдено: `{"candidates": []}`.

**Промпт:** `prompts/llm_extractor.txt`.

**Когда работает:** Параллельно с газеттером и regex на Фазе 1. Результаты объединяются
с кандидатами других экстракторов на Фазе 2.

### LLM-обогатитель (Фаза 4)

**Задача:** Подобрать альтернативные названия для кандидата, не разрешённого через
iNaturalist.

**Вход:** Нормализованное кандидатное название + одно предложение контекста.
Контекст передаётся для языковой подсказки; LLM опирается на само название.

**Выход:**

```json
{
  "common_names_ru": ["..."],
  "common_names_en": ["..."]
}
```

Пустые массивы допустимы.

**Промпт:** `prompts/llm_enricher.txt`.

**Когда работает:** На Фазе 4, только для кандидатов, не разрешённых через iNaturalist.

### Чанкинг для LLM-экстрактора

Текст разбивается на чанки для отправки в LLM. Параметры задаются в конфигурации
(`llm_extractor`):

| Параметр | Описание | По умолчанию |
|----------|----------|-------------|
| `chunk_strategy` | Стратегия разбиения: `"paragraph"` или `"page"` | `"paragraph"` |
| `min_chunk_words` | Минимальный размер чанка (слов) | 50 |
| `max_chunk_words` | Максимальный размер чанка (слов) | 500 |

**Алгоритм для `"paragraph"`:**
1. Текст разбивается по двойному переносу строки (`\n\n`).
2. Абзацы короче `min_chunk_words` склеиваются с последующими до достижения минимума.
3. Абзацы длиннее `max_chunk_words` разбиваются по границам предложений
   (spaCy `doc.sents`).

**Алгоритм для `"page"`:**
1. Текст разбивается на чанки по `max_chunk_words` слов.
2. Границы чанков выравниваются по предложениям (не разрывать предложение).

**Fallback (скользящее окно):** Если после разбиения остаются чанки, превышающие
`max_chunk_words` (например, одно предложение длиннее лимита), применяется скользящее
окно с перекрытием ~50 слов.

### Обработка ошибок LLM

Правила одинаковы для обеих ролей:
1. Невалидный JSON (markdown-обёртка, trailing comma, лишний текст) — попытка очистки
   и парсинга (strip markdown fences, fix trailing commas).
2. При неудаче — повтор запроса (до 2 раз).
3. При стабильном невалидном ответе — WARNING в лог:
   - LLM-экстрактор: чанк пропускается (кандидаты из него не добавляются).
   - LLM-обогатитель: кандидат получает `identified: "no"`,
     `reason: "LLM returned invalid response"`.

## Нормализация текста

Нормализация применяется к кандидатам перед поиском в iNaturalist и при сравнении
для определения `identified`.

Шаги:
1. Приведение к нижнему регистру.
2. Замена `ё` на `е` (оригинальная форма сохраняется как дополнительный вариант поиска).
3. Лемматизация через pymorphy3 (для русских слов). spaCy используется для токенизации,
   но для корректной леммы русских слов (особенно редких/биологических) используется
   pymorphy3 напрямую. Для многословных названий — лемматизация каждого слова отдельно.
4. Для латинских слов — только lowercase, без лемматизации.

Результат — набор вариантов для поиска:
- оригинальная форма (lowercase),
- форма с заменой ё→е,
- лемматизированная форма,
- лемматизированная форма с заменой ё→е.

## Модель extraction_confidence

Значение `extraction_confidence` зависит от метода извлечения и **количества таксонов**,
на которые маппится совпавшее название в газеттере (фактор неоднозначности).

| Метод | Условие | confidence |
|-------|---------|------------|
| Газеттер, exact match | 1 taxon_id в газеттере | 1.0 |
| Газеттер, exact match | 2+ taxon_id (неоднозначность) | 0.8 |
| Газеттер, lemma match | 1 taxon_id | 0.9 |
| Газеттер, lemma match | 2+ taxon_id | 0.7 |
| Regex | подтверждён газеттером (`taxon_name` найден) | 0.9 |
| Regex | не найден в газеттере | 0.7 |
| LLM | по умолчанию (или значение от LLM, не более 0.8) | 0.6 |

**Фактор неоднозначности:** если `name_normalized` маппится на N различных `taxon_id`
в газеттере, confidence снижается. Это отражает тот факт, что омонимичные названия
(например, «журавль» — и птица, и народное название нескольких растений) менее надёжны
как идентификатор конкретного таксона.

## Критерии identified

`identified` определяется после разрешения через iNaturalist (Фаза 3) или напрямую
из газеттера (для кандидатов, пропустивших Фазу 3).

Сравнение выполняется **по обоим вариантам**: нормализованная форма (lowercase, ё→е)
**и** лемматизированная форма. Совпадение любого варианта считается успешным.

`identified: "yes"` если хотя бы один результат удовлетворяет одному из условий:
- нормализованная или лемматизированная форма `source_text` совпадает с аналогичной
  формой любого `taxon_common_name` из результатов (для заданного `locale`);
- нормализованная или лемматизированная форма `source_text` совпадает с `taxon_name`
  (латинское название, lowercase);
- `source_text` (после нормализации) найден среди `names` таксона в ответе iNaturalist.

`identified: "no"` если ни одно условие не выполнено. В этом случае `matches` может
быть непустым (содержать ближайших кандидатов), но `candidate_names` и `reason`
обязательны.

## Правила вычисления line_number и source_context

- `line_number`: номер строки (1-based) из входного файла. Строки считаются по символу
  `\n`. Если вхождение пересекает несколько строк — берётся строка начала совпадения.
- `source_context`: одно предложение, содержащее вхождение. Предложение определяется
  через `doc.sents` из spaCy, который корректно обрабатывает сокращения (г., т.е.,
  и т.д.) и не разбивает предложение на них. Fallback на границы строки (`\n`)
  при недоступности сегментации.

## Дедупликация и кэширование

### Дедупликация

Книга может упоминать одно название сотни раз. После объединения кандидатов из всех
экстракторов:
- Кандидаты группируются по нормализованной лемме.
- Каждый уникальный кандидат разрешается через iNaturalist один раз.
- Результат разрешения хранится в памяти и применяется ко всем вхождениям.

### Кэширование

Два уровня:

1. **In-memory** (обязательный): словарь `normalized_lemma → resolution_result`,
   живёт в пределах одного запуска. Обеспечивает дедупликацию.
2. **Disk-кэш** (опциональный): SQLite-база `cache/taxonfinder.db`. Хранит пары
   `(query, locale) → iNaturalist response` с TTL (7 дней по умолчанию). Позволяет
   не повторять запросы при повторном запуске на том же или похожем тексте.

### Версионирование баз данных

Обе SQLite-базы (газеттер и disk-кэш) содержат таблицу `schema_version`:

```sql
CREATE TABLE schema_version (
    version INTEGER NOT NULL,
    created_at TEXT NOT NULL DEFAULT (datetime('now'))
);
```

При запуске приложение проверяет `version` и завершается с понятным сообщением
об ошибке при несовместимой версии схемы. При обновлении схемы базы данных
версия инкрементируется.
