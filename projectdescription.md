## Описание проекта

Я натуралист, и я пользователь inaturalist.org. Сейчас я увлёкся чтением книг о живой природе.
Я читаю книги про природу, в которых упоминаются таксоны растений и животных. Иногда это таксоны,
указанные как латинские научные названия, иногда как народные названия. Я хочу уметь сканировать
весь текст книги и получать список таксонов, упоминающихся в нём, чтобы быстро просматривать их
на inaturalist.org.

Итак, мне требуется приложение, которое будет принимать на вход большой текст, а на выходе давать
JSON-файл, в котором для каждого вхождения названия растения или животного будет указано
соответствующее латинское название таксона, а также значение поля `taxon_id` на inaturalist.org.

## Технический стек

Извлечение названий таксонов из текста — гибридный подход из трёх методов:

1. **Газеттер (dictionary-based matching)** — основной метод для народных названий. Список
   русских и латинских common names выгружается из iNaturalist и загружается в spaCy
   `PhraseMatcher`. Даёт предсказуемый recall для известных названий.
2. **Regex-детектор латинских биномиалов** — отдельный проход для латинских научных названий
   вида *Tilia cordata*, *Quercus robur* (заглавная буква + строчные, 2–3 слова). Не требует
   NER и работает надёжно для стандартной номенклатуры.
3. **LLM-экстракция** — для названий, не пойманных газеттером и regex. LLM получает фрагмент
   текста и извлекает из него кандидатные названия организмов. Работает через Ollama на
   MacBook Air M3 24 GB. Вместо local-LLM могут быть использованы API облачных AI (например,
   OpenAI, Anthropic или Perplexity), но на первом этапе — local.

spaCy используется как NLP-движок для:
- токенизации и сегментации текста на предложения (`doc.sents`),
- лемматизации (дополняется pymorphy3 для корректной русской морфологии),
- `PhraseMatcher` для газеттера.

Верификация и обогащение данных — через iNaturalist API (pyinaturalist). iNaturalist является
финальным источником истины: все кандидаты, найденные любым методом, проверяются через API.

## Архитектура модулей

Код организован как Python-пакет с чётким разделением ответственности. Ядро пайплайна не зависит
от CLI или веб-фреймворка, что позволяет использовать его как backend для Flask/FastAPI.

```
taxonfinder/
  __init__.py
  cli.py              # CLI entry point
  config.py           # Загрузка и валидация конфигурации
  pipeline.py         # Оркестрация: текст → результат
  extractors/
    __init__.py
    gazetteer.py      # Dictionary-based matching через spaCy PhraseMatcher
    latin.py          # Regex-детектор латинских биномиалов
    llm.py            # LLM-экстракция (абстракция + реализация Ollama)
  resolvers/
    __init__.py
    inaturalist.py    # Верификация и поиск через iNaturalist API
    cache.py          # Кэш результатов (in-memory + опциональный disk)
  models.py           # Dataclasses для внутренних структур данных
  normalizer.py       # Нормализация текста, лемматизация
```

Ключевой контракт: `pipeline.process(text: str, config: Config) -> list[ResultItem]` — чистая
функция, которая принимает текст и конфигурацию, возвращает результат. CLI и будущий
веб-эндпоинт вызывают одну и ту же функцию.

## Входные данные

Как исходные данные должен использоваться путь к файлу формата `txt`, лежащий в папке проекта
и содержащий текст на русском языке (с возможными латинскими вкраплениями — научными названиями),
содержащий искомые имена растений и животных. Формального контракта для входа не требуется: это
обычный текстовый файл в UTF-8.

При необходимости может использоваться аутентификация inaturalist.org для пользования их API.

## Режим работы

Приложение должно работать в режиме CLI.

## Пользовательские настройки

Нужен файл пользовательских настроек в формате JSON. Файл лежит в корне проекта и валидируется
строгой JSON-схемой.

- Файл: `taxonfinder.config.json`
- JSON-схема: `schemas/config.schema.json`

Поля конфигурации:
- `confidence`: number, минимальный порог `extraction_confidence` (0.0–1.0) для включения
  результата в выходной файл.
- `locale`: string, значение передаётся в iNaturalist API как Locale preference for taxon common
  names.
- `llm_prompt_file`: string, путь к файлу с промптом для LLM (относительно корня проекта).
  Промпт хранится в отдельном текстовом файле, а не inline в JSON, для удобства редактирования
  и версионирования. Файл по умолчанию: `prompts/taxon_extraction.txt`.
- `llm_provider`: string, провайдер LLM. Допустимые значения: `"ollama"`, `"openai"`,
  `"anthropic"`. По умолчанию: `"ollama"`.
- `llm_model`: string, имя модели для выбранного провайдера (например, `"llama3.1"`,
  `"gemma2"`, `"gpt-4o-mini"`).
- `llm_url`: string, URL для подключения к LLM (для Ollama — `http://localhost:11434`).
  Для облачных провайдеров может быть опущен (используется стандартный endpoint).
- `llm_timeout`: number, таймаут ожидания ответа LLM в секундах. По умолчанию: `30`.

## Выходные данные

Конечный результат должен выводиться в виде JSON-файла.

### JSON-схема результата

Формат: массив объектов (каждый объект — одно вхождение).
Строгая JSON-схема: `schemas/output.schema.json`.

Обязательные поля:
- `line_number`: integer, номер строки (1-based), где встречено вхождение.
- `source_text`: string, исходное слово/фраза в тексте (как в оригинале, без нормализации).
- `source_context`: string, предложение, в котором встретилось вхождение.
- `identified`: "yes" | "no", удалось ли однозначно определить таксон.
- `extraction_confidence`: number (0.0–1.0), уверенность в том, что извлечённый фрагмент
  является названием таксона. Значение зависит от метода извлечения:
  - газеттер (точное совпадение): `1.0`;
  - газеттер (fuzzy / после лемматизации): `0.9`;
  - regex (латинский биномиал): `0.95`;
  - LLM-экстракция: значение выставляется LLM (или фиксированное `0.7`, если LLM не
    возвращает confidence).
- `extraction_method`: string, метод, которым найден кандидат. Допустимые значения:
  `"gazetteer"`, `"latin_regex"`, `"llm"`.
- `matches`: array[object], список результатов из iNaturalist (до 5), отсортированных по
  убыванию `score` из API; если `score` равен — по алфавиту `taxon_common_name`, а при его
  отсутствии — `taxon_name`.
- `llm_response`: object | null, ответ LLM (если к ней обращались).

Поля каждого элемента `matches` (на основе данных iNaturalist через pyinaturalist):
- `taxon_id`: integer, `id` таксона в iNaturalist.
- `taxon_name`: string, научное имя (латиница), соответствует `name`.
- `taxon_rank`: string, таксономический ранг (например, `species`, `genus`), соответствует
  `rank`.
- `taxon_common_name`: string | null, предпочитаемое общее имя, соответствует
  `preferred_common_name` (если доступно).
- `taxon_matched_name`: string, имя, по которому найден таксон, либо нормализованное имя,
  если найдено через LLM.
- `taxon_url`: string, ссылка на таксон (формируется как
  `https://www.inaturalist.org/taxa/{taxon_id}`).

Поля для неидентифицированных (но вероятных) таксонов:
- `candidate_names`: array[string], список кандидатных латинских/народных названий из LLM
  и газеттера.
- `reason`: string, краткое объяснение, почему не удалось подтвердить таксон.

Пример записи:

```json
{
  "line_number": 10,
  "source_context": "На перевале мы встретили множество огромных лип, растущих, словно великаны, здесь уже более двух веков.",
  "source_text": "лип",
  "identified": "yes",
  "extraction_confidence": 0.9,
  "extraction_method": "gazetteer",
  "matches": [
    {
      "taxon_id": 54586,
      "taxon_name": "Tilia",
      "taxon_rank": "genus",
      "taxon_common_name": "Linden",
      "taxon_matched_name": "липа",
      "taxon_url": "https://www.inaturalist.org/taxa/54586"
    }
  ],
  "llm_response": null
}
```

## Пайплайн обработки

Обработка текста выполняется в четыре фазы.

### Фаза 1: Предобработка и извлечение кандидатов

1. Текст загружается и обрабатывается через spaCy: токенизация, сегментация на предложения
   (`doc.sents`), лемматизация.
2. Параллельно запускаются три экстрактора:
   - **Газеттер**: spaCy `PhraseMatcher` ищет совпадения с известными названиями из словаря.
     Совпадения ищутся как по оригинальной форме, так и по лемме (через pymorphy3).
   - **Regex-детектор**: ищет латинские биномиалы по паттерну
     `[A-Z][a-z]+ [a-z]+( [a-z]+)?`.
   - **LLM-экстрактор**: текст разбивается на фрагменты (по предложениям или абзацам),
     каждый фрагмент передаётся в LLM с просьбой извлечь названия организмов.
3. Результаты всех экстракторов объединяются в общий список кандидатов. Каждый кандидат
   содержит: исходный текст, лемму, позицию в тексте, метод извлечения, confidence.

### Фаза 2: Дедупликация кандидатов

1. Кандидаты группируются по нормализованной лемме.
2. Для каждой уникальной леммы выбирается один представитель — кандидат с наибольшим
   `extraction_confidence`.
3. Формируется список уникальных кандидатов для разрешения через iNaturalist.

### Фаза 3: Разрешение через iNaturalist

1. Каждый уникальный кандидат отправляется в iNaturalist API (поиск по `q` параметру).
2. Результаты кэшируются (см. раздел «Дедупликация и кэширование»).
3. Для каждого кандидата формируется список matches (до 5 результатов).
4. Определяется значение `identified` (см. раздел «Критерии identified»).

### Фаза 4: Сборка результата

1. Разрешённые данные «раскладываются» обратно по всем вхождениям: если "липа" встречается
   30 раз, разрешение выполняется 1 раз, а результат копируется для всех 30 вхождений
   (с корректными `line_number`, `source_text`, `source_context`).
2. Результат фильтруется по порогу `confidence` из конфигурации.
3. Формируется итоговый JSON-массив.

## Правила вычисления `line_number` и `source_context`

- `line_number`: номер строки (1-based) из входного `txt`. Строки считаются по символу `\n`.
  Если вхождение пересекает несколько строк, берётся строка, где начинается совпадение.
- `source_context`: одно предложение, содержащее вхождение. Предложение определяется через
  `doc.sents` из spaCy, который корректно обрабатывает сокращения (г., т.е., и т.д.) и не
  разбивает предложение на них. Если сегментация spaCy недоступна — fallback на границы
  строки (`\n`).

## Нормализация текста

Нормализация применяется к кандидатам перед поиском в iNaturalist и при сравнении для
определения `identified`.

Шаги нормализации:
1. Приведение к нижнему регистру.
2. Замена `ё` на `е` с сохранением оригинальной формы как дополнительного варианта поиска.
3. Лемматизация через pymorphy3 (основной лемматизатор для русского языка). spaCy
   используется для токенизации, но для получения корректной леммы русских слов (особенно
   редких/биологических) используется pymorphy3 напрямую.
4. Для многословных названий ("дикая коза") — лемматизация каждого слова с последующей
   склейкой.

Результат нормализации — набор вариантов для поиска:
- оригинальная форма (lowercase),
- форма с заменой ё→е,
- лемматизированная форма,
- лемматизированная форма с заменой ё→е.

## Дедупликация и кэширование

### Дедупликация

Книга может упоминать одно и то же название сотни раз. Дедупликация обязательна:
- Перед обращением к LLM и iNaturalist кандидаты группируются по нормализованной лемме.
- Каждый уникальный кандидат разрешается один раз.
- Результат разрешения хранится в памяти и применяется ко всем вхождениям.

### Кэширование

Два уровня кэша:

1. **In-memory кэш** (обязательный): словарь `normalized_lemma → resolution_result`, живёт
   в пределах одного запуска. Обеспечивает дедупликацию.
2. **Disk-кэш** (опциональный, включается в конфигурации): SQLite-база в
   `cache/taxonfinder.db`. Хранит пары `(query, locale) → iNaturalist response` с TTL
   (по умолчанию 7 дней). Позволяет не повторять запросы при повторном запуске на том же
   или похожем тексте.

## Порядок обращения к LLM

Обращение к LLM не требуется, если кандидат найден газеттером или regex и успешно
верифицирован через iNaturalist.

Порядок:
1. Если кандидат — латинский биномиал (найден regex) → сразу в iNaturalist, без LLM.
2. Если кандидат найден газеттером (точное или лемма-совпадение с known name) → сразу
   в iNaturalist, без LLM.
3. Если кандидат найден газеттером или regex, но iNaturalist не вернул результат → обращение
   к LLM для получения альтернативных названий, затем повторный поиск в iNaturalist.
4. Если кандидат найден только через LLM-экстракцию → LLM уже вернул данные, передаём
   в iNaturalist для верификации.

Результаты LLM всегда верифицируются через iNaturalist; iNaturalist является финальной точкой
принятия решения.

## Формат ответа LLM

LLM обязана возвращать строго JSON-объект следующей формы:

```json
{
  "common_names_ru": ["..."],
  "common_names_en": ["..."]
}
```

- `common_names_ru`: массив русских народных названий.
- `common_names_en`: массив английских народных названий.
- Пустые массивы допустимы.

Вход в LLM:
- нормализованное вхождение + одно предложение контекста (ограничить длину), контекст
  передаётся для языковой подсказки, но LLM должна опираться на само вхождение.
- промпт явно требует: «используй только это имя, контекст — лишь для понимания языка».

Обработка ошибок LLM:
- Если LLM вернул невалидный JSON (markdown-обёртка, trailing comma, лишний текст) —
  попытка вычистить и распарсить (strip markdown fences, fix trailing commas).
- При неудаче — повтор запроса (до 2 раз).
- При стабильном невалидном ответе — логирование WARNING, кандидат помечается как
  `identified: "no"` с `reason: "LLM returned invalid response"`.

## Критерии `identified`

Сравнение выполняется **по лемме**, а не побуквенно, чтобы учесть склонение русских слов.

- `identified: "yes"` если хотя бы один результат из iNaturalist удовлетворяет одному
  из условий:
  - лемма `source_text` совпадает с леммой любого `taxon_common_name` из результатов
    iNaturalist (для заданного `locale`);
  - лемма `source_text` совпадает с леммой `taxon_name` (латинское название);
  - `source_text` (после нормализации) найден среди `names` таксона в ответе iNaturalist.
- Лемматизация выполняется через pymorphy3 для русских слов и простой lowercase для
  латинских.
- `identified: "no"` если ни одно из условий выше не выполнено. В этом случае `matches`
  может быть непустым (содержать ближайших кандидатов), но `candidate_names` и `reason`
  обязательны.

## Ограничения по API

- Тайминг: не более 1 запроса к iNaturalist в 1 секунду.
- При ошибках API повторять запрос до 3 раз с нарастающим таймаутом, начиная с 3 секунд.
- Таймауты iNaturalist API: подключение 5 секунд, чтение 20 секунд, общий лимит 30 секунд.
- Кэширование (in-memory — обязательное, disk — опциональное) снижает число реальных
  обращений к API (см. раздел «Дедупликация и кэширование»).

## Режим CLI

Формат запуска:

```
taxonfinder <input.txt> [output.json]
```

- `input.txt` — обязательный путь к входному файлу.
- `output.json` — опциональный путь к выходному файлу. Если не задан, вывод печатается
  в консоль.
- `--config` — опциональный путь к файлу конфигурации. По умолчанию:
  `taxonfinder.config.json` в текущей директории.

## Обработка ошибок

Ошибки и нештатные ситуации должны обрабатываться. Специальные error code не требуются, но для
фатальных ошибок используется ненулевой код выхода и сообщение в `stderr`.

## Логи CLI

- Формат логов: текстовые строки с ISO-8601 временем, уровнем, сообщением и контекстом.
- Уровни: `DEBUG`, `INFO`, `WARNING`, `ERROR`.
- Логи пишутся в `logs/taxonfinder.log` в корне проекта; файл создаётся автоматически.

## Примечания по обновлению связанных файлов

Следующие файлы требуют обновления в соответствии с изменениями в этом документе:
- `schemas/output.schema.json` — переименовать `ner_confidence` → `extraction_confidence`,
  добавить поле `extraction_method`.
- `schemas/config.schema.json` — добавить поля `llm_provider`, `llm_model`, `llm_url`,
  `llm_timeout`, `llm_prompt_file`; убрать `llm_prompt`.
- `taxonfinder.config.json` — привести в соответствие новой схеме.
- `tests/data/*.json` — обновить фикстуры.
- `pyproject.toml` — добавить секцию `[project]` с зависимостями и CLI entry point.
