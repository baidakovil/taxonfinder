## Описание проекта

Я натуралист, и я пользователь inaturalist.org. Сейчас я увлёкся чтением книг о живой природе.
Я читаю книги про природу, в которых упоминаются таксоны растений и животных. Иногда это таксоны,
указанные как латинские научные названия, иногда как народные названия. Я хочу уметь сканировать
весь текст книги и получать список таксонов, упоминающихся в нём, чтобы быстро просматривать их
на inaturalist.org.

Итак, мне требуется приложение, которое будет принимать на вход большой текст, а на выходе давать
JSON-файл, в котором для каждого вхождения названия растения или животного будет указано
соответствующее латинское название таксона, а также значение поля `taxon_id` на inaturalist.org.

## Технический стек

Извлечение названий таксонов из текста — гибридный подход из трёх методов:

1. **Газеттер (dictionary-based matching)** — основной метод для народных названий. Список
   русских и латинских common names выгружается из iNaturalist и загружается в spaCy
   `PhraseMatcher`. Даёт предсказуемый recall для известных названий.
2. **Regex-детектор латинских биномиалов** — отдельный проход для латинских научных названий
   вида *Tilia cordata*, *Quercus robur* (заглавная буква + строчные, 2–3 слова). Не требует
   NER и работает надёжно для стандартной номенклатуры. Для снижения ложных срабатываний
   применяются эвристические фильтры (см. раздел «Regex-детектор: правила валидации»).
3. **LLM** — используется в двух независимых ролях, каждая из которых может быть включена
   или отключена отдельно:
   - **LLM-экстрактор** (Фаза 1): получает фрагменты текста (абзацы или страницы) и извлекает
     из них названия организмов, не пойманные газеттером и regex. Работает параллельно
     с другими экстракторами. Отправляет текст крупными чанками (не по предложениям),
     что делает обработку книги реалистичной по времени.
   - **LLM-обогатитель** (Фаза 4): получает кандидатное название, не разрешённое через
     iNaturalist, и возвращает альтернативные народные/научные названия для повторного поиска.
   Работает через Ollama на MacBook Air M3 24 GB. Вместо local-LLM могут быть использованы
   API облачных AI (например, OpenAI, Anthropic), но на первом этапе — local. Для каждой
   роли можно задать свою модель и провайдера.

spaCy используется как NLP-движок для:
- токенизации и сегментации текста на предложения (`doc.sents`),
- лемматизации (дополняется pymorphy3 для корректной русской морфологии),
- `PhraseMatcher` для газеттера.

Верификация и обогащение данных — через iNaturalist API (pyinaturalist). iNaturalist является
финальным источником истины: все кандидаты, найденные любым методом, проверяются через API.

## Архитектура модулей

Код организован как Python-пакет с чётким разделением ответственности. Ядро пайплайна не зависит
от CLI или веб-фреймворка, что позволяет использовать его как backend для Flask/FastAPI.

```
taxonfinder/
  __init__.py
  cli.py                # CLI entry point
  config.py             # Загрузка и валидация конфигурации
  pipeline.py           # Оркестрация: генератор PipelineEvent (sync + async)
  events.py             # Dataclasses для PipelineEvent, PipelineSummary
  loaders/
    __init__.py         # load_text() — автовыбор загрузчика по расширению
    base.py             # TextLoader Protocol
    plain_text.py       # PlainTextLoader (.txt, UTF-8)
  extractors/
    __init__.py
    gazetteer.py        # Dictionary-based matching через spaCy PhraseMatcher
    latin.py            # Regex-детектор латинских биномиалов + валидация
    llm_extractor.py    # LLM-экстракция названий из текста (Фаза 1)
    llm_enricher.py     # LLM-обогащение неразрешённых кандидатов (Фаза 4)
    llm_client.py       # Абстракция LLM-клиента (Ollama, OpenAI, Anthropic)
  resolvers/
    __init__.py
    inaturalist.py      # Верификация и поиск через iNaturalist API
    cache.py            # Кэш результатов (in-memory + опциональный disk)
  gazetteer/
    __init__.py
    builder.py          # Построение газеттера из данных iNaturalist (pyinaturalist)
    storage.py          # Чтение/запись SQLite-базы газеттера
  models.py             # Dataclasses для внутренних структур данных
  normalizer.py         # Нормализация текста, лемматизация

data/
  gazetteer.db          # SQLite-база газеттера (генерируется builder'ом)

prompts/
  llm_extractor.txt     # Промпт для LLM-экстрактора (Фаза 1)
  llm_enricher.txt      # Промпт для LLM-обогатителя (Фаза 4)
```

### Ключевой контракт пайплайна

Пайплайн реализован как **генератор**, который yield'ит события по мере обработки.
Это обеспечивает стриминг результатов, отчёт о прогрессе и возможность отмены.

```python
# Синхронный генератор (для CLI)
def process(text: str, config: Config) -> Iterator[PipelineEvent]:
    ...

# Асинхронный генератор (для веб-бэкенда)
async def process_async(text: str, config: Config) -> AsyncIterator[PipelineEvent]:
    ...

# Convenience-обёртка для получения только результатов
def process_all(text: str, config: Config) -> list[ResultItem]:
    return [e.item for e in process(text, config) if isinstance(e, ResultReady)]
```

Типы событий (`PipelineEvent` — union/dataclass):
- `PhaseStarted(phase: str, total: int)` — начало фазы, `total` — количество элементов.
- `PhaseProgress(phase: str, current: int, total: int, detail: str)` — прогресс фазы.
- `ResultReady(item: ResultItem)` — готовый элемент результата (Фаза 5 yield'ит по мере
  сборки).
- `PipelineFinished(summary: PipelineSummary)` — завершение: статистика по методам,
  количество найденных/неидентифицированных, время каждой фазы.

CLI подписывается на `PhaseProgress` для отображения прогресс-бара.
Веб-бэкенд использует `process_async` и транслирует события через SSE/WebSocket.
Оба варианта вызывают одно и то же ядро логики.

## Газеттер: данные и формат хранения

Газеттер — основной экстрактор, обеспечивающий предсказуемый recall для известных названий.
Данные для газеттера загружаются из iNaturalist API через pyinaturalist и хранятся в локальной
SQLite-базе (`data/gazetteer.db`). Детали реализации загрузчика (фильтрация по контрольному
списку, place_id и т.д.) определяются отдельно; здесь описано, **что** должно быть загружено
и в каком формате хранится.

### Требуемые данные

Для каждого таксона, попадающего в газеттер, необходимы:
- **taxon_id** — идентификатор таксона в iNaturalist.
- **taxon_name** — научное (латинское) название (`name` из API).
- **taxon_rank** — таксономический ранг (`rank`: species, genus, family и т.д.).
- **ancestry** — цепочка предковых таксонов (`ancestry` из API), для возможной будущей
  фильтрации по таксономическому дереву.
- **Все common names** для настроенных локалей (как минимум `ru` и `en`), включая:
  - само название (`name`),
  - флаг предпочитаемого названия (`is_preferred`),
  - локаль (`locale`),
  - источник (`lexicon`).

Источник данных: поля `name`, `rank`, `ancestry`, `preferred_common_name`, `names` из
объектов Taxon, получаемых через pyinaturalist.

### Схема SQLite-базы газеттера

```sql
CREATE TABLE taxa (
    taxon_id INTEGER PRIMARY KEY,   -- iNaturalist taxon ID
    taxon_name TEXT NOT NULL,        -- Scientific name (e.g. "Tilia cordata")
    taxon_rank TEXT NOT NULL,        -- Rank (e.g. "species", "genus")
    ancestry TEXT                    -- Taxonomic ancestry path
);

CREATE TABLE common_names (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    taxon_id INTEGER NOT NULL REFERENCES taxa(taxon_id),
    name TEXT NOT NULL,              -- Original common name
    name_normalized TEXT NOT NULL,   -- Lowercased, ё → е
    name_lemmatized TEXT,            -- Lemmatized via pymorphy3 (для русских названий)
    locale TEXT NOT NULL,            -- Language code ("ru", "en", ...)
    is_preferred BOOLEAN DEFAULT 0,  -- Preferred name for this locale
    lexicon TEXT                     -- Source lexicon (e.g. "iNaturalist")
);

CREATE INDEX idx_cn_normalized ON common_names(name_normalized);
CREATE INDEX idx_cn_lemmatized ON common_names(name_lemmatized);
CREATE INDEX idx_cn_locale ON common_names(locale);
CREATE INDEX idx_cn_taxon ON common_names(taxon_id);
```

### Загрузка в runtime

При старте приложения газеттер:
1. Открывает `data/gazetteer.db` (путь задаётся в конфигурации, поле `gazetteer_path`).
2. Загружает все значения `name_normalized` и `name_lemmatized` для настроенной локали
   в spaCy `PhraseMatcher`.
3. Хранит в памяти маппинг `name_normalized → list[taxon_id]` для быстрого поиска при
   совпадении.

При обнаружении совпадения PhraseMatcher возвращает span, по которому из маппинга
извлекаются `taxon_id`, а затем из SQLite — полная информация о таксоне.

### Оценка объёма

Газеттер не загружает все таксоны iNaturalist (их миллионы). Набор ограничивается
критериями загрузчика (контрольный список, place_id, iconic taxa и т.д.). Ориентировочный
размер для рабочего набора: 50 000–200 000 common names. PhraseMatcher с таким количеством
паттернов потребляет ~100–500 МБ RAM и инициализируется за несколько секунд.

### Обновление газеттера

Газеттер строится отдельной CLI-командой (`taxonfinder build-gazetteer`) и не обновляется
автоматически при каждом запуске. Пересборка выполняется вручную при необходимости.

## Входные данные

На вход подаётся путь к файлу, содержащему текст на русском языке (с возможными латинскими
вкраплениями — научными названиями). Загрузка текста из файла выполняется через абстракцию
`TextLoader`, что позволяет поддерживать несколько форматов без изменения ядра пайплайна.

### Абстракция TextLoader

```python
class TextLoader(Protocol):
    """Protocol for loading text from various file formats."""

    def supports(self, path: Path) -> bool:
        """Return True if this loader can handle the given file."""
        ...

    def load(self, path: Path) -> str:
        """Load and return plain text content from the file."""
        ...
```

Функция `load_text(path: Path) -> str` автоматически выбирает подходящий загрузчик
по расширению файла. Если формат не поддерживается — ошибка с понятным сообщением.

### Поддерживаемые форматы

| Формат | Расширение | Реализация | Статус |
|--------|-----------|------------|--------|
| Plain text | `.txt` | `PlainTextLoader` — чтение UTF-8 | v0.1 (MVP) |
| EPUB | `.epub` | `EpubLoader` — извлечение текста из EPUB-архива | планируется |
| PDF | `.pdf` | `PdfLoader` — извлечение текста из PDF | планируется |

Для первой версии реализуется только `PlainTextLoader`. Остальные загрузчики добавляются
по мере необходимости; ядро пайплайна работает с `str` и не зависит от формата входного
файла.

### Требования к входному тексту

- Кодировка: UTF-8.
- Язык: русский (с возможными латинскими научными названиями).
- Формального контракта для содержимого не требуется: это обычный текст.

При необходимости может использоваться аутентификация inaturalist.org для пользования их API.

## Режим работы

Приложение должно работать в режиме CLI.

## Пользовательские настройки

Нужен файл пользовательских настроек в формате JSON. Файл лежит в корне проекта и валидируется
строгой JSON-схемой.

- Файл: `taxonfinder.config.json`
- JSON-схема: `schemas/config.schema.json`

Поля конфигурации:
- `confidence`: number, минимальный порог `extraction_confidence` (0.0–1.0) для включения
  результата в выходной файл.
- `locale`: string, значение передаётся в iNaturalist API как Locale preference for taxon common
  names.
- `gazetteer_path`: string, путь к SQLite-базе газеттера (относительно корня проекта).
  По умолчанию: `"data/gazetteer.db"`.
- `llm_extractor`: object | null, настройки LLM-экстрактора (Фаза 1). Если `null` или
  отсутствует — LLM-экстрактор отключён.
  - `enabled`: boolean, включён ли экстрактор. По умолчанию: `true`.
  - `provider`: string, провайдер. Допустимые значения: `"ollama"`, `"openai"`, `"anthropic"`.
  - `model`: string, имя модели (например, `"llama3.1"`, `"gpt-4o-mini"`).
  - `url`: string, URL для подключения (для Ollama — `http://localhost:11434`).
  - `timeout`: number, таймаут в секундах. По умолчанию: `60`.
  - `prompt_file`: string, путь к файлу с промптом. По умолчанию:
    `"prompts/llm_extractor.txt"`.
  - `chunk_strategy`: string, стратегия разбиения текста на чанки. Допустимые значения:
    `"paragraph"`, `"page"`. По умолчанию: `"paragraph"`.
- `llm_enricher`: object | null, настройки LLM-обогатителя (Фаза 4). Если `null` или
  отсутствует — LLM-обогатитель отключён.
  - `enabled`: boolean, включён ли обогатитель. По умолчанию: `true`.
  - `provider`: string, провайдер. Допустимые значения: `"ollama"`, `"openai"`, `"anthropic"`.
  - `model`: string, имя модели.
  - `url`: string, URL для подключения.
  - `timeout`: number, таймаут в секундах. По умолчанию: `30`.
  - `prompt_file`: string, путь к файлу с промптом. По умолчанию:
    `"prompts/llm_enricher.txt"`.

## Выходные данные

Конечный результат должен выводиться в виде JSON-файла.

### JSON-схема результата

Формат: массив объектов (каждый объект — одно вхождение).
Строгая JSON-схема: `schemas/output.schema.json`.

Обязательные поля:
- `line_number`: integer, номер строки (1-based), где встречено вхождение.
- `source_text`: string, исходное слово/фраза в тексте (как в оригинале, без нормализации).
- `source_context`: string, предложение, в котором встретилось вхождение.
- `identified`: "yes" | "no", удалось ли однозначно определить таксон.
- `extraction_confidence`: number (0.0–1.0), уверенность в том, что извлечённый фрагмент
  является названием таксона. Значение зависит от метода извлечения:
  - газеттер (точное совпадение): `1.0`;
  - газеттер (fuzzy / после лемматизации): `0.9`;
  - regex (латинский биномиал): `0.95`;
  - LLM-экстракция: значение выставляется LLM (или фиксированное `0.7`, если LLM не
    возвращает confidence).
- `extraction_method`: string, метод, которым найден кандидат. Допустимые значения:
  `"gazetteer"`, `"latin_regex"`, `"llm"`.
- `matches`: array[object], список результатов из iNaturalist (до 5), отсортированных по
  убыванию `score` из API; если `score` равен — по алфавиту `taxon_common_name`, а при его
  отсутствии — `taxon_name`.
- `llm_response`: object | null, ответ LLM (если к ней обращались).

Поля каждого элемента `matches` (на основе данных iNaturalist через pyinaturalist):
- `taxon_id`: integer, `id` таксона в iNaturalist.
- `taxon_name`: string, научное имя (латиница), соответствует `name`.
- `taxon_rank`: string, таксономический ранг (например, `species`, `genus`), соответствует
  `rank`.
- `taxon_common_name`: string | null, предпочитаемое общее имя, соответствует
  `preferred_common_name` (если доступно).
- `taxon_matched_name`: string, имя, по которому найден таксон, либо нормализованное имя,
  если найдено через LLM.
- `taxon_url`: string, ссылка на таксон (формируется как
  `https://www.inaturalist.org/taxa/{taxon_id}`).

Поля для неидентифицированных (но вероятных) таксонов:
- `candidate_names`: array[string], список кандидатных латинских/народных названий из LLM
  и газеттера.
- `reason`: string, краткое объяснение, почему не удалось подтвердить таксон.

Пример записи:

```json
{
  "line_number": 10,
  "source_context": "На перевале мы встретили множество огромных лип, растущих, словно великаны, здесь уже более двух веков.",
  "source_text": "лип",
  "identified": "yes",
  "extraction_confidence": 0.9,
  "extraction_method": "gazetteer",
  "matches": [
    {
      "taxon_id": 54586,
      "taxon_name": "Tilia",
      "taxon_rank": "genus",
      "taxon_common_name": "Linden",
      "taxon_matched_name": "липа",
      "taxon_url": "https://www.inaturalist.org/taxa/54586"
    }
  ],
  "llm_response": null
}
```

## Пайплайн обработки

Обработка текста выполняется в пять фаз.

### Фаза 1: Загрузка, предобработка и извлечение кандидатов

1. Текст загружается из входного файла через `TextLoader` (автовыбор загрузчика по
   расширению, см. раздел «Входные данные»).
2. Текст обрабатывается через spaCy: токенизация, сегментация на предложения
   (`doc.sents`), лемматизация.
3. Запускаются экстракторы (параллельно, где возможно):
   - **Газеттер** (всегда): spaCy `PhraseMatcher` ищет совпадения с известными названиями
     из SQLite-базы газеттера. Совпадения ищутся как по оригинальной форме, так и по лемме
     (через pymorphy3).
   - **Regex-детектор** (всегда): ищет латинские биномиалы по паттерну
     `[A-Z][a-z]+ [a-z]+( [a-z]+)?`. Кандидаты проходят эвристическую валидацию:
     фильтр длины, стоп-лист, проверка по газеттеру, контекстная эвристика
     (см. раздел «Regex-детектор: правила валидации»).
   - **LLM-экстрактор** (опционально, включается в конфигурации): текст разбивается на
     чанки (по абзацам или страницам, в зависимости от `chunk_strategy`), каждый чанк
     передаётся в LLM с просьбой извлечь названия организмов. Крупные чанки (абзац или
     страница) минимизируют количество LLM-вызовов: книга в 300 страниц = ~300–700 вызовов,
     а не тысячи.
4. Результаты всех активных экстракторов объединяются в общий список кандидатов. Каждый
   кандидат содержит: исходный текст, лемму, позицию в тексте, метод извлечения, confidence.

### Фаза 2: Merge и дедупликация кандидатов

1. Кандидаты из всех экстракторов объединяются в единый список.
2. При перекрытии (один и тот же span найден несколькими экстракторами) сохраняется кандидат
   с наивысшим `extraction_confidence`. Приоритет: газеттер > regex > LLM.
3. Кандидаты группируются по нормализованной лемме.
4. Для каждой уникальной леммы выбирается один представитель для разрешения через iNaturalist.
5. Все вхождения (включая дубли) сохраняются для Фазы 5.

### Фаза 3: Разрешение через iNaturalist

1. Каждый уникальный кандидат отправляется в iNaturalist API (поиск по `q` параметру).
2. Результаты кэшируются (см. раздел «Дедупликация и кэширование»).
3. Для каждого кандидата формируется список matches (до 5 результатов).
4. Определяется значение `identified` (см. раздел «Критерии identified»).

### Фаза 4: LLM-обогащение неразрешённых кандидатов

Эта фаза выполняется только если LLM-обогатитель включён в конфигурации.

1. Кандидаты, для которых iNaturalist не вернул результатов (пустой `matches`) или
   `identified: "no"`, передаются в LLM-обогатитель.
2. LLM-обогатитель получает кандидатное название + контекстное предложение и возвращает
   альтернативные названия (русские и английские common names).
3. Альтернативные названия отправляются в iNaturalist для повторного поиска.
4. Результаты повторного поиска объединяются с существующими matches.

### Фаза 5: Сборка результата

1. Разрешённые данные «раскладываются» обратно по всем вхождениям: если "липа" встречается
   30 раз, разрешение выполняется 1 раз, а результат копируется для всех 30 вхождений
   (с корректными `line_number`, `source_text`, `source_context`).
2. Результат фильтруется по порогу `confidence` из конфигурации.
3. Формируется итоговый JSON-массив.

## Прогресс, стриминг и асинхронный интерфейс

### Прогресс

Обработка книги — длительная операция (минуты–десятки минут). Пайплайн-генератор
yield'ит события `PhaseProgress` на каждом значимом шаге:
- Фаза 1: после обработки каждого чанка LLM-экстрактором.
- Фаза 3: после каждого запроса к iNaturalist API.
- Фаза 4: после каждого запроса к LLM-обогатителю.

CLI использует события для прогресс-бара (через `click.progressbar` или аналог).
Веб-бэкенд транслирует события клиенту через SSE или WebSocket.

### Стриминг результатов

Результаты (события `ResultReady`) yield'ятся на Фазе 5 по мере сборки, а не после
завершения всей обработки. Это позволяет:
- CLI: выводить результаты инкрементально (например, в режиме `--stream`).
- Веб-бэкенд: отправлять готовые элементы клиенту до завершения обработки.

### Асинхронный интерфейс

Для использования в веб-бэкенде (FastAPI, aiohttp) предусмотрен `process_async` —
асинхронный генератор с тем же контрактом событий. Внутри он использует `httpx.AsyncClient`
для запросов к iNaturalist и LLM-провайдерам. Синхронный `process` реализуется как обёртка
над `process_async` через `asyncio.run` или как отдельная реализация с синхронным I/O.

Оба варианта разделяют одну и ту же бизнес-логику (экстракторы, нормализация,
дедупликация, критерии identified). Различается только I/O-слой.

## Правила вычисления `line_number` и `source_context`

- `line_number`: номер строки (1-based) из входного `txt`. Строки считаются по символу `\n`.
  Если вхождение пересекает несколько строк, берётся строка, где начинается совпадение.
- `source_context`: одно предложение, содержащее вхождение. Предложение определяется через
  `doc.sents` из spaCy, который корректно обрабатывает сокращения (г., т.е., и т.д.) и не
  разбивает предложение на них. Если сегментация spaCy недоступна — fallback на границы
  строки (`\n`).

## Нормализация текста

Нормализация применяется к кандидатам перед поиском в iNaturalist и при сравнении для
определения `identified`.

Шаги нормализации:
1. Приведение к нижнему регистру.
2. Замена `ё` на `е` с сохранением оригинальной формы как дополнительного варианта поиска.
3. Лемматизация через pymorphy3 (основной лемматизатор для русского языка). spaCy
   используется для токенизации, но для получения корректной леммы русских слов (особенно
   редких/биологических) используется pymorphy3 напрямую.
4. Для многословных названий ("дикая коза") — лемматизация каждого слова с последующей
   склейкой.

Результат нормализации — набор вариантов для поиска:
- оригинальная форма (lowercase),
- форма с заменой ё→е,
- лемматизированная форма,
- лемматизированная форма с заменой ё→е.

## Regex-детектор: правила валидации

Базовый паттерн `[A-Z][a-z]+ [a-z]+( [a-z]+)?` ловит латинские биномиалы, но даёт
ложные срабатывания на небиологических латинских фразах, именах собственных и географических
названиях. В русскоязычном тексте проблема смягчена (латиница выделяется на фоне кириллицы),
но фильтрация всё равно необходима.

### Эвристические фильтры (применяются последовательно)

1. **Минимальная длина слов**: оба слова биномиала должны содержать >= 3 символов.
   Это отсекает паттерны типа "In vitro", "Ad hoc".
2. **Стоп-лист латинских фраз**: набор распространённых небиологических латинских выражений,
   исключаемых из кандидатов. Примеры: "Et cetera", "Ad libitum", "In situ", "Ex vivo",
   "De facto", "Pro rata", "Per se", "Ab initio", "Status quo", "Modus operandi",
   "Alma mater", "Anno domini". Стоп-лист хранится как константа в `extractors/latin.py`
   и может быть расширен.
3. **Проверка по газеттеру**: если regex-совпадение найдено в таблице `taxa.taxon_name`
   газеттера — кандидат подтверждён (confidence `0.95`). Это быстрая локальная проверка
   без обращения к API.
4. **Контекстная эвристика**: если совпадение следует непосредственно за обращением
   (Mr., Dr., Prof., von, van) — вероятно имя человека, кандидат отклоняется.

### Порядок применения

```
regex match → фильтр длины → стоп-лист → проверка газеттера → контекстная эвристика
            → прошёл все фильтры? → кандидат (confidence 0.95)
```

Кандидаты, прошедшие фильтры, но не найденные в газеттере, всё равно отправляются
в iNaturalist для верификации на Фазе 3. Финальное решение принимает iNaturalist.

## Дедупликация и кэширование

### Дедупликация

Книга может упоминать одно и то же название сотни раз. Дедупликация обязательна:
- После объединения кандидатов из всех экстракторов (газеттер, regex, LLM-экстрактор)
  кандидаты группируются по нормализованной лемме.
- Каждый уникальный кандидат разрешается через iNaturalist один раз.
- Результат разрешения хранится в памяти и применяется ко всем вхождениям.

### Кэширование

Два уровня кэша:

1. **In-memory кэш** (обязательный): словарь `normalized_lemma → resolution_result`, живёт
   в пределах одного запуска. Обеспечивает дедупликацию.
2. **Disk-кэш** (опциональный, включается в конфигурации): SQLite-база в
   `cache/taxonfinder.db`. Хранит пары `(query, locale) → iNaturalist response` с TTL
   (по умолчанию 7 дней). Позволяет не повторять запросы при повторном запуске на том же
   или похожем тексте.

## Роли и порядок обращения к LLM

LLM используется в двух независимых ролях. Каждая роль имеет свой промпт, контракт
ввода-вывода и может быть включена или отключена отдельно.

### LLM-экстрактор (Фаза 1)

**Задача:** Найти в тексте названия организмов, которые газеттер и regex не обнаружили.
Газеттер конечен по определению; LLM-экстрактор — единственный способ обнаружить
региональные, просторечные и устаревшие названия, отсутствующие в словаре.

**Вход:** Чанк текста (абзац или страница). Размер чанка определяется `chunk_strategy`
в конфигурации. Абзацы разделяются двойным переносом строки (`\n\n`); страницы —
фиксированным лимитом (~350 слов / ~1500 токенов).

**Выход (формат ответа):**

```json
{
  "candidates": [
    {"name": "чёртово дерево", "context": "первые слова предложения..."},
    {"name": "горный баран", "context": "первые слова предложения..."}
  ]
}
```

- `candidates`: массив объектов. Каждый объект содержит найденное название и краткий
  контекст (начало предложения, в котором оно встречено).
- Если организмов в чанке не найдено — пустой массив: `{"candidates": []}`.

**Промпт:** `prompts/llm_extractor.txt`. Инструктирует LLM найти все упоминания организмов
(растений, животных, грибов и т.д.), включая народные, просторечные и устаревшие названия.

**Когда работает:** Параллельно с газеттером и regex на Фазе 1. Результаты объединяются
с кандидатами других экстракторов на Фазе 2.

### LLM-обогатитель (Фаза 4)

**Задача:** Подобрать альтернативные названия для кандидата, которого iNaturalist не смог
разрешить напрямую.

**Вход:** Нормализованное кандидатное название + одно предложение контекста (ограничить
длину). Контекст передаётся для языковой подсказки, но LLM должна опираться на само
название.

**Выход (формат ответа):**

```json
{
  "common_names_ru": ["..."],
  "common_names_en": ["..."]
}
```

- `common_names_ru`: массив русских народных названий.
- `common_names_en`: массив английских народных названий.
- Пустые массивы допустимы.

**Промпт:** `prompts/llm_enricher.txt`. Явно требует: «используй только это имя, контекст —
лишь для понимания языка».

**Когда работает:** На Фазе 4, только для кандидатов, не разрешённых через iNaturalist.

### Порядок взаимодействия с LLM в пайплайне

1. **Фаза 1** — LLM-экстрактор (если включён) обрабатывает весь текст по чанкам,
   параллельно с газеттером и regex.
2. **Фаза 2** — результаты LLM-экстрактора объединяются с результатами газеттера и regex.
   При перекрытии приоритет у газеттера/regex (выше confidence).
3. **Фаза 3** — все уникальные кандидаты (независимо от метода извлечения) отправляются
   в iNaturalist.
4. **Фаза 4** — LLM-обогатитель (если включён) обрабатывает только неразрешённые кандидаты.

Результаты LLM всегда верифицируются через iNaturalist; iNaturalist является финальной точкой
принятия решения.

### Обработка ошибок LLM

Правила одинаковы для обеих ролей:
- Если LLM вернул невалидный JSON (markdown-обёртка, trailing comma, лишний текст) —
  попытка вычистить и распарсить (strip markdown fences, fix trailing commas).
- При неудаче — повтор запроса (до 2 раз).
- При стабильном невалидном ответе — логирование WARNING.
  - Для LLM-экстрактора: чанк пропускается (кандидаты из него не добавляются).
  - Для LLM-обогатителя: кандидат помечается как `identified: "no"` с
    `reason: "LLM returned invalid response"`.

## Критерии `identified`

Сравнение выполняется **по лемме**, а не побуквенно, чтобы учесть склонение русских слов.

- `identified: "yes"` если хотя бы один результат из iNaturalist удовлетворяет одному
  из условий:
  - лемма `source_text` совпадает с леммой любого `taxon_common_name` из результатов
    iNaturalist (для заданного `locale`);
  - лемма `source_text` совпадает с леммой `taxon_name` (латинское название);
  - `source_text` (после нормализации) найден среди `names` таксона в ответе iNaturalist.
- Лемматизация выполняется через pymorphy3 для русских слов и простой lowercase для
  латинских.
- `identified: "no"` если ни одно из условий выше не выполнено. В этом случае `matches`
  может быть непустым (содержать ближайших кандидатов), но `candidate_names` и `reason`
  обязательны.

## Ограничения по API

- Тайминг: не более 1 запроса к iNaturalist в 1 секунду.
- При ошибках API повторять запрос до 3 раз с нарастающим таймаутом, начиная с 3 секунд.
- Таймауты iNaturalist API: подключение 5 секунд, чтение 20 секунд, общий лимит 30 секунд.
- Кэширование (in-memory — обязательное, disk — опциональное) снижает число реальных
  обращений к API (см. раздел «Дедупликация и кэширование»).

## Режим CLI

Формат запуска:

```
taxonfinder <input.txt> [output.json]
```

- `input.txt` — обязательный путь к входному файлу.
- `output.json` — опциональный путь к выходному файлу. Если не задан, вывод печатается
  в консоль.
- `--config` — опциональный путь к файлу конфигурации. По умолчанию:
  `taxonfinder.config.json` в текущей директории.

## Обработка ошибок

Ошибки и нештатные ситуации должны обрабатываться. Специальные error code не требуются, но для
фатальных ошибок используется ненулевой код выхода и сообщение в `stderr`.

## Логи CLI

- Формат логов: текстовые строки с ISO-8601 временем, уровнем, сообщением и контекстом.
- Уровни: `DEBUG`, `INFO`, `WARNING`, `ERROR`.
- Логи пишутся в `logs/taxonfinder.log` в корне проекта; файл создаётся автоматически.

## Примечания по обновлению связанных файлов

Следующие файлы были обновлены в соответствии с этим документом:
- `schemas/config.schema.json` — структура LLM-конфигурации разделена на `llm_extractor`
  и `llm_enricher`; добавлено поле `gazetteer_path`.
- `taxonfinder.config.json` — приведён в соответствие новой схеме.
- `prompts/llm_extractor.txt` — промпт для LLM-экстрактора (новый файл).
- `prompts/llm_enricher.txt` — промпт для LLM-обогатителя (новый файл, заменяет
  `prompts/taxon_extraction.txt`).

Следующие файлы требуют обновления при дальнейшей разработке:
- `schemas/output.schema.json` — актуализировать при изменении выходного формата.
- `tests/data/*.json` — обновить фикстуры при изменении формата.
- `pyproject.toml` — актуален; при реализации добавить зависимости для будущих загрузчиков
  (epub, pdf) как optional dependencies.
