## Описание проекта

Приложение для извлечения названий таксонов (растений, животных, грибов и т.д.) из текстов
на русском языке. На вход подаётся текст книги, на выходе — JSON-файл со списком обнаруженных
таксонов, их латинскими названиями и ссылками на iNaturalist.

Целевой сценарий: натуралист читает книгу о природе и хочет получить полный список
упомянутых организмов с возможностью перехода на iNaturalist.org.

## Технический стек

Извлечение названий таксонов — гибридный подход из трёх методов:

1. **Газеттер (dictionary-based matching)** — основной метод для народных названий. Список
   русских и латинских common names хранится в локальной SQLite-базе и загружается в spaCy
   `PhraseMatcher`. Даёт предсказуемый recall для известных названий.
2. **Regex-детектор латинских биномиалов** — отдельный проход для научных латинских названий
   вида *Tilia cordata*, *Quercus robur*. Не требует NER, работает надёжно для стандартной
   номенклатуры. Для снижения ложных срабатываний применяются эвристические фильтры.
3. **LLM** — используется в двух независимых ролях (каждая включается/отключается отдельно):
   - **LLM-экстрактор** (Фаза 1): получает чанки текста и извлекает названия организмов,
     не пойманные газеттером и regex.
   - **LLM-обогатитель** (Фаза 4): подбирает альтернативные названия для кандидатов,
     не разрешённых через iNaturalist.

Верификация и обогащение данных — через iNaturalist API (httpx). iNaturalist является
финальным источником истины: все кандидаты, найденные любым методом, проверяются через API
(за исключением газеттерных совпадений с полными данными — см. оптимизацию Фазы 3).

### Основные зависимости

| Зависимость | Назначение |
|-------------|-----------|
| **spaCy** | Токенизация, сегментация на предложения (`doc.sents`), `PhraseMatcher` для газеттера. Модель: `ru_core_news_md` (конфигурируется через `spacy_model` в конфиге) |
| **pymorphy3** | Лемматизация русских слов (дополняет spaCy для корректной русской морфологии) |
| **httpx** | HTTP-клиент для iNaturalist API и LLM-провайдеров (единый клиент для sync I/O) |
| **jsonschema** | Валидация конфигурации |
| **click** | CLI-интерфейс |
| **structlog** | Structured logging (JSON в production, human-readable в CLI) |
| **python-dotenv** | Загрузка секретов (API-ключей) из `.env` файла |
| **charset-normalizer** | Автоопределение кодировки входного файла (fallback при не-UTF-8) |

LLM работает через Ollama (local, MacBook Air M3 24 GB) или через API облачных провайдеров
(OpenAI, Anthropic). Для каждой роли LLM можно задать свою модель и провайдера.

Взаимодействие с iNaturalist API выполняется напрямую через httpx (эндпоинты
`/v1/taxa/autocomplete`, `/v1/taxa/{id}` и др.). Библиотека-обёртка pyinaturalist
не используется.

## Архитектура

### Модули

Код организован как Python-пакет с чётким разделением ответственности. Ядро пайплайна
не зависит от CLI или веб-фреймворка, что позволяет использовать его как backend
для Flask/FastAPI.

```
taxonfinder/
  __init__.py
  cli.py                # CLI entry point (Click)
  config.py             # Загрузка и валидация конфигурации
  pipeline.py           # Оркестрация: sync-генератор PipelineEvent
  events.py             # Dataclasses для PipelineEvent, PipelineSummary
  logging.py            # Настройка structlog (JSON / human-readable)
  rate_limiter.py       # Token-bucket rate limiter для HTTP-запросов
  checkpoint.py         # Сохранение/загрузка промежуточного состояния
  loaders/
    __init__.py         # load_text() — автовыбор загрузчика по расширению
    base.py             # TextLoader Protocol
    plain_text.py       # PlainTextLoader (.txt, UTF-8)
  extractors/
    __init__.py
    gazetteer.py        # Dictionary-based matching через spaCy PhraseMatcher
    latin.py            # Regex-детектор латинских биномиалов + валидация
    llm_extractor.py    # LLM-экстракция названий из текста (Фаза 1)
    llm_enricher.py     # LLM-обогащение неразрешённых кандидатов (Фаза 4)
    llm_client.py       # Абстракция LLM-клиента (Ollama, OpenAI, Anthropic)
  resolvers/
    __init__.py
    base.py             # TaxonSearcher и IdentificationResolver Protocols
    inaturalist.py      # Поиск таксонов через iNaturalist API (httpx)
    identifier.py       # Логика определения identified (сравнение имён)
    cache.py            # Кэш результатов (in-memory + опциональный disk)
  gazetteer/
    __init__.py
    builder.py          # Построение газеттера из данных iNaturalist
    storage.py          # Чтение/запись SQLite-базы газеттера
  models.py             # Dataclasses для внутренних структур данных
  normalizer.py         # Нормализация текста, лемматизация

data/
  gazetteer.db          # SQLite-база газеттера (генерируется builder'ом)
  control_list/         # CSV-файлы с контрольными списками таксонов

prompts/
  llm_extractor.txt     # Промпт для LLM-экстрактора (Фаза 1)
  llm_enricher.txt      # Шаблонизированный промпт для LLM-обогатителя (Фаза 4)
```

### Контракт пайплайна

Пайплайн реализован как **синхронный генератор**, который yield'ит события по мере
обработки. Это обеспечивает стриминг результатов, отчёт о прогрессе и возможность отмены.

```python
def process(
    text: str,
    config: Config,
    *,
    searcher: TaxonSearcher | None = None,
    identifier: IdentificationResolver | None = None,
    llm_client: LlmClient | None = None,
    rate_limiter: RateLimiter | None = None,
) -> Iterator[PipelineEvent]:
    """Основной sync-генератор. Ядро пайплайна.

    Зависимости принимаются через keyword-аргументы для тестируемости.
    Если не переданы — создаются из config (production defaults).
    """
    ...

def process_all(text: str, config: Config, **kwargs) -> list[TaxonResult]:
    """Convenience-обёртка: возвращает только итоговые результаты."""
    return [e.result for e in process(text, config, **kwargs)
            if isinstance(e, ResultReady)]

def estimate(text: str, config: Config) -> PipelineEstimate:
    """Dry-run: оценка объёма работы без выполнения."""
    ...
```

Типы событий (`PipelineEvent` — union/dataclass):
- `PhaseStarted(phase: str, total: int)` — начало фазы, `total` — количество элементов.
- `PhaseProgress(phase: str, current: int, total: int, detail: str)` — прогресс фазы.
- `ResultReady(result: TaxonResult)` — готовый элемент результата.
- `PipelineFinished(summary: PipelineSummary)` — завершение: статистика по методам,
  количество найденных/неидентифицированных, время каждой фазы.

> **Примечание:** Поле `identified` в Python-моделях и в JSON-выводе имеет тип
> `bool` (`true`/`false`). См. [docs/models.md](docs/models.md) для подробностей.

CLI подписывается на `PhaseProgress` для отображения прогресс-бара.

### Синхронное ядро и граница async

Ядро пайплайна — **полностью синхронное** (осознанный выбор для MVP: простота
отладки, предсказуемый поток данных, минимум абстракций). Все HTTP-запросы
(iNaturalist API, LLM-провайдеры) выполняются через `httpx.Client`
(синхронный клиент).

Для использования в веб-бэкенде синхронный генератор оборачивается на уровне
веб-слоя. Подробности — в разделе [Web API контракт](#web-api-контракт).

Ядро (`taxonfinder/`) не импортирует `asyncio` и не содержит `async/await`.
Весь async-код принадлежит веб-адаптеру, который не является частью v0.1.

#### Подготовка к веб-бэкенду

Чтобы синхронное ядро можно было корректно использовать в async-контексте:
1. **Все зависимости передаются через DI** (keyword-аргументы `process()`)
   — нет глобального состояния, каждый вызов изолирован.
2. **`httpx.Client` — thread-safe** и может обслуживать несколько потоков
   через `ThreadPoolExecutor`.
3. **Генератор PipelineEvent** совместим с SSE: каждое событие сериализуется
   в JSON и отправляется клиенту.
4. **Checkpoint** позволяет сохранять промежуточное состояние на диск,
   что критично при долгих обработках в веб-контексте.

### Web API контракт

Веб-адаптер (Flask/FastAPI) не является частью MVP, но архитектура ядра
проектируется для его поддержки.

**Транспорт: Server-Sent Events (SSE).** Генератор `PipelineEvent` естественно
ложится на SSE — каждое событие отправляется клиенту по мере готовности.
SSE проще WebSocket (однонаправленный), не требует библиотек на клиенте
(стандартный `EventSource`), работает через HTTP/1.1.

**Эндпоинты:**

```
POST /api/v1/tasks
  Body: {"text": "...", "config_overrides": {...}}
  Response: {"task_id": "uuid", "status": "queued"}

GET  /api/v1/tasks/{task_id}/events
  Response: SSE stream of PipelineEvent (Content-Type: text/event-stream)
  Events:
    event: phase_started\ndata: {"phase": "extraction", "total": 42}\n\n
    event: phase_progress\ndata: {"phase": "extraction", "current": 1, ...}\n\n
    event: result_ready\ndata: {"result": {...}}\n\n
    event: pipeline_finished\ndata: {"summary": {...}}\n\n

GET  /api/v1/tasks/{task_id}
  Response: {"task_id": "...", "status": "running|completed|failed", ...}

DELETE /api/v1/tasks/{task_id}
  Response: 204 (отмена обработки через generator.close())
```

**Реализация:**

```python
# web/adapter.py — не часть ядра пайплайна
import asyncio
import queue
import threading
from taxonfinder.pipeline import process

def run_pipeline_in_thread(
    text: str, config: Config, event_queue: queue.Queue
) -> None:
    """Запускает синхронный пайплайн в отдельном потоке,
    отправляя события в thread-safe очередь."""
    try:
        for event in process(text, config):
            event_queue.put(event)
    except Exception as exc:
        event_queue.put(exc)
    finally:
        event_queue.put(None)  # sentinel
```

Веб-адаптер запускает `run_pipeline_in_thread` в `ThreadPoolExecutor`
и читает из `event_queue` для формирования SSE-ответа.

**Ограничения конкурентности:** текущая архитектура (синхронное ядро +
thread pool) поддерживает **1–3 задачи одновременно**. Каждая задача
занимает поток и выполняет блокирующие HTTP-запросы. Для масштабируемости
(десятки одновременных задач) задача обработки должна уходить в task queue
(Celery, RQ, Dramatiq) — воркер-процесс исполняет синхронный генератор
без изменений, а веб-адаптер только принимает задачу и отдаёт статус.
Это не требует переписывания ядра — синхронный генератор отлично работает
в воркер-процессе task queue.

**httpx.Client и `User-Agent`:** Все HTTP-клиенты (iNaturalist API,
LLM-провайдеры) должны устанавливать заголовок `User-Agent` с именем
и версией приложения (например, `TaxonFinder/0.1.0`). Это требование
iNaturalist API guidelines — без корректного User-Agent запросы могут
быть ограничены.

### Механизм отмены

Отмена обработки поддерживается через стандартный механизм Python-генераторов:

- **CLI:** при получении SIGINT (Ctrl+C) вызывается `generator.close()`. Генератор
  получает `GeneratorExit`, выполняет cleanup и завершается.
- **Веб-бэкенд:** отмена `asyncio.Task` приводит к завершению потока, в котором
  работает генератор.

Пайплайн обрабатывает `GeneratorExit` корректно: закрывает HTTP-соединения через
`httpx.Client` context manager, сохраняет промежуточные данные disk-кэша.

## Пайплайн обработки

Обработка текста выполняется в пять фаз. Подробности алгоритмов описаны
в [docs/processing.md](docs/processing.md).

### Фаза 1: Загрузка, предобработка и извлечение кандидатов

1. Текст загружается из входного файла через `TextLoader` (автовыбор по расширению).
2. Текст обрабатывается через spaCy: токенизация, сегментация на предложения, лемматизация.
3. Запускаются экстракторы:
   - **Газеттер** (если доступен): spaCy PhraseMatcher ищет совпадения с известными названиями.
   - **Regex-детектор** (всегда): ищет латинские биномиалы с эвристической валидацией.
   - **LLM-экстрактор** (если включён): текст разбивается на чанки и отправляется в LLM.
4. Результаты объединяются в общий список кандидатов.

> При `degraded_mode: true` в конфигурации отсутствие газеттера не является
> фатальной ошибкой — пайплайн продолжает с доступными экстракторами (regex, LLM),
> выдавая WARNING. При `degraded_mode: false` (по умолчанию) отсутствие газеттера —
> фатальная ошибка.

### Фаза 2: Merge и дедупликация кандидатов

1. Кандидаты из всех экстракторов объединяются.
2. При перекрытии spans сохраняется кандидат с наивысшим `extraction_confidence`.
   Приоритет при равенстве: газеттер > regex > LLM.
3. Кандидаты группируются по нормализованной лемме.
4. Для каждой уникальной леммы выбирается один представитель для разрешения.
5. Все вхождения (включая дубли) сохраняются для Фазы 5.

### Фаза 3: Разрешение через iNaturalist

1. **Оптимизация: пропуск газеттерных кандидатов с полными данными.** Кандидаты,
   найденные газеттером, для которых SQLite-база газеттера уже содержит все поля,
   необходимые для формирования выходной записи (`taxon_id`, `taxon_name`, `taxon_rank`,
   `taxon_common_name`), **пропускают Фазу 3**. Обращение к iNaturalist API для них
   не выполняется — данные берутся напрямую из газеттера.
2. Остальные кандидаты (regex, LLM, газеттерные с неполными данными) отправляются
   в iNaturalist API (endpoint `/v1/taxa/autocomplete`).
3. Результаты кэшируются (in-memory, опционально disk).
4. Для каждого кандидата формируется список matches (до 5 результатов).
5. Определяется значение `identified`
   (см. [критерии](docs/processing.md#критерии-identified)).

### Фаза 4: LLM-обогащение неразрешённых кандидатов

Выполняется только если LLM-обогатитель включён в конфигурации.

1. Кандидаты с пустым `matches` или `identified: false` передаются в LLM-обогатитель.
2. LLM получает кандидатное название + контекстное предложение, возвращает альтернативные
   русские и английские названия.
3. Альтернативные названия отправляются в iNaturalist для повторного поиска.
4. Результаты повторного поиска объединяются с существующими matches.

### Фаза 5: Сборка результата

1. Разрешённые данные раскладываются по всем вхождениям: если «липа» встречается 30 раз,
   разрешение выполняется 1 раз, а результат применяется ко всем 30 вхождениям.
2. Результат фильтруется по порогу `confidence` из конфигурации.
3. Формируется итоговый JSON:
   - **По умолчанию (дедуплицированный режим):** одна запись на уникальный таксон
     с полем `count` и массивом `occurrences` (каждое вхождение с `line_number`,
     `source_text`, `source_context`).
   - **С флагом `--all-occurrences`:** одна запись на каждое вхождение (без группировки).

## Прогресс

Обработка книги — длительная операция (минуты–десятки минут). Генератор yield'ит
`PhaseProgress` на каждом значимом шаге:
- Фаза 1: после обработки каждого LLM-чанка.
- Фаза 3: после каждого запроса к iNaturalist API.
- Фаза 4: после каждого запроса к LLM-обогатителю.

CLI использует события для прогресс-бара (`click.progressbar` или аналог).

## Управление секретами

API-ключи (OpenAI, Anthropic) **никогда не хранятся в конфигурационном файле**.
Они загружаются из переменных окружения или `.env` файла (через `python-dotenv`):

```
# .env (добавлен в .gitignore)
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
```

`config.py` при загрузке конфигурации вызывает `dotenv.load_dotenv()`, что загружает
переменные окружения из `.env` файла в `os.environ`. LLM-клиенты (OpenAI, Anthropic)
читают API-ключи из `os.environ` при инициализации. Провайдер `ollama` не требует ключа.

## Подробная документация

- [Модели данных](docs/models.md) — внутренние структуры, поток данных между фазами,
  события пайплайна, протоколы.
- [Обработка и алгоритмы](docs/processing.md) — экстракторы, нормализация, confidence,
  identified, LLM, чанкинг, дедупликация, кэширование.
- [Форматы данных и CLI](docs/data-and-cli.md) — входные/выходные форматы, конфигурация,
  CLI, ограничения API, обработка ошибок.
