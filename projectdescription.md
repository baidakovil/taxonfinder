## Описание проекта

Приложение для извлечения названий таксонов (растений, животных, грибов и т.д.) из текстов
на русском языке. На вход подаётся текст книги, на выходе — JSON-файл со списком обнаруженных
таксонов, их латинскими названиями и ссылками на iNaturalist.

Целевой сценарий: натуралист читает книгу о природе и хочет получить полный список
упомянутых организмов с возможностью перехода на iNaturalist.org.

## Технический стек

Извлечение названий таксонов — гибридный подход из трёх методов:

1. **Газеттер (dictionary-based matching)** — основной метод для народных названий. Список
   русских и латинских common names хранится в локальной SQLite-базе и загружается в spaCy
   `PhraseMatcher`. Даёт предсказуемый recall для известных названий.
2. **Regex-детектор латинских биномиалов** — отдельный проход для научных латинских названий
   вида *Tilia cordata*, *Quercus robur*. Не требует NER, работает надёжно для стандартной
   номенклатуры. Для снижения ложных срабатываний применяются эвристические фильтры.
3. **LLM** — используется в двух независимых ролях (каждая включается/отключается отдельно):
   - **LLM-экстрактор** (Фаза 1): получает чанки текста и извлекает названия организмов,
     не пойманные газеттером и regex.
   - **LLM-обогатитель** (Фаза 4): подбирает альтернативные названия для кандидатов,
     не разрешённых через iNaturalist.

Верификация и обогащение данных — через iNaturalist API (httpx). iNaturalist является
финальным источником истины: все кандидаты, найденные любым методом, проверяются через API
(за исключением газеттерных совпадений с полными данными — см. оптимизацию Фазы 3).

### Основные зависимости

| Зависимость | Назначение |
|-------------|-----------|
| **spaCy** | Токенизация, сегментация на предложения (`doc.sents`), `PhraseMatcher` для газеттера |
| **pymorphy3** | Лемматизация русских слов (дополняет spaCy для корректной русской морфологии) |
| **httpx** | HTTP-клиент для iNaturalist API и LLM-провайдеров (единый клиент для sync I/O) |
| **jsonschema** | Валидация конфигурации |
| **click** | CLI-интерфейс |

LLM работает через Ollama (local, MacBook Air M3 24 GB) или через API облачных провайдеров
(OpenAI, Anthropic). Для каждой роли LLM можно задать свою модель и провайдера.

Взаимодействие с iNaturalist API выполняется напрямую через httpx (эндпоинты
`/v1/taxa/autocomplete`, `/v1/taxa/{id}` и др.). Библиотека-обёртка pyinaturalist
не используется.

## Архитектура

### Модули

Код организован как Python-пакет с чётким разделением ответственности. Ядро пайплайна
не зависит от CLI или веб-фреймворка, что позволяет использовать его как backend
для Flask/FastAPI.

```
taxonfinder/
  __init__.py
  cli.py                # CLI entry point (Click)
  config.py             # Загрузка и валидация конфигурации
  pipeline.py           # Оркестрация: sync-генератор PipelineEvent
  events.py             # Dataclasses для PipelineEvent, PipelineSummary
  loaders/
    __init__.py         # load_text() — автовыбор загрузчика по расширению
    base.py             # TextLoader Protocol
    plain_text.py       # PlainTextLoader (.txt, UTF-8)
  extractors/
    __init__.py
    gazetteer.py        # Dictionary-based matching через spaCy PhraseMatcher
    latin.py            # Regex-детектор латинских биномиалов + валидация
    llm_extractor.py    # LLM-экстракция названий из текста (Фаза 1)
    llm_enricher.py     # LLM-обогащение неразрешённых кандидатов (Фаза 4)
    llm_client.py       # Абстракция LLM-клиента (Ollama, OpenAI, Anthropic)
  resolvers/
    __init__.py
    inaturalist.py      # Поиск и верификация через iNaturalist API (httpx)
    cache.py            # Кэш результатов (in-memory + опциональный disk)
  gazetteer/
    __init__.py
    builder.py          # Построение газеттера из данных iNaturalist
    storage.py          # Чтение/запись SQLite-базы газеттера
  models.py             # Dataclasses для внутренних структур данных
  normalizer.py         # Нормализация текста, лемматизация

data/
  gazetteer.db          # SQLite-база газеттера (генерируется builder'ом)

prompts/
  llm_extractor.txt     # Промпт для LLM-экстрактора (Фаза 1)
  llm_enricher.txt      # Промпт для LLM-обогатителя (Фаза 4)
```

### Контракт пайплайна

Пайплайн реализован как **синхронный генератор**, который yield'ит события по мере
обработки. Это обеспечивает стриминг результатов, отчёт о прогрессе и возможность отмены.

```python
def process(text: str, config: Config) -> Iterator[PipelineEvent]:
    """Основной sync-генератор. Ядро пайплайна."""
    ...

def process_all(text: str, config: Config) -> list[TaxonResult]:
    """Convenience-обёртка: возвращает только итоговые результаты."""
    return [e.result for e in process(text, config) if isinstance(e, ResultReady)]

def estimate(text: str, config: Config) -> PipelineEstimate:
    """Dry-run: оценка объёма работы без выполнения."""
    ...
```

Типы событий (`PipelineEvent` — union/dataclass):
- `PhaseStarted(phase: str, total: int)` — начало фазы, `total` — количество элементов.
- `PhaseProgress(phase: str, current: int, total: int, detail: str)` — прогресс фазы.
- `ResultReady(result: TaxonResult)` — готовый элемент результата.
- `PipelineFinished(summary: PipelineSummary)` — завершение: статистика по методам,
  количество найденных/неидентифицированных, время каждой фазы.

CLI подписывается на `PhaseProgress` для отображения прогресс-бара.

### Синхронное ядро и граница async

Ядро пайплайна — **полностью синхронное**. Все HTTP-запросы (iNaturalist API,
LLM-провайдеры) выполняются через `httpx.Client` (синхронный клиент).

Для использования в веб-бэкенде (Flask, FastAPI) синхронный генератор оборачивается
на уровне веб-слоя через `asyncio.to_thread` или `concurrent.futures.ThreadPoolExecutor`:

```python
# Веб-адаптер (не часть ядра пайплайна)
import asyncio
from taxonfinder.pipeline import process

async def process_web(text: str, config: Config):
    """Async-обёртка для веб-фреймворков. Делегирует в thread pool."""
    for event in await asyncio.to_thread(lambda: list(process(text, config))):
        yield event
```

Ядро (`taxonfinder/`) не импортирует `asyncio` и не содержит `async/await`.
Весь async-код принадлежит веб-адаптеру, который не является частью v0.1.

### Механизм отмены

Отмена обработки поддерживается через стандартный механизм Python-генераторов:

- **CLI:** при получении SIGINT (Ctrl+C) вызывается `generator.close()`. Генератор
  получает `GeneratorExit`, выполняет cleanup и завершается.
- **Веб-бэкенд:** отмена `asyncio.Task` приводит к завершению потока, в котором
  работает генератор.

Пайплайн обрабатывает `GeneratorExit` корректно: закрывает HTTP-соединения через
`httpx.Client` context manager, сохраняет промежуточные данные disk-кэша.

## Пайплайн обработки

Обработка текста выполняется в пять фаз. Подробности алгоритмов описаны
в [docs/processing.md](docs/processing.md).

### Фаза 1: Загрузка, предобработка и извлечение кандидатов

1. Текст загружается из входного файла через `TextLoader` (автовыбор по расширению).
2. Текст обрабатывается через spaCy: токенизация, сегментация на предложения, лемматизация.
3. Параллельно запускаются экстракторы:
   - **Газеттер** (всегда): spaCy PhraseMatcher ищет совпадения с известными названиями.
   - **Regex-детектор** (всегда): ищет латинские биномиалы с эвристической валидацией.
   - **LLM-экстрактор** (если включён): текст разбивается на чанки и отправляется в LLM.
4. Результаты объединяются в общий список кандидатов.

### Фаза 2: Merge и дедупликация кандидатов

1. Кандидаты из всех экстракторов объединяются.
2. При перекрытии spans сохраняется кандидат с наивысшим `extraction_confidence`.
   Приоритет при равенстве: газеттер > regex > LLM.
3. Кандидаты группируются по нормализованной лемме.
4. Для каждой уникальной леммы выбирается один представитель для разрешения.
5. Все вхождения (включая дубли) сохраняются для Фазы 5.

### Фаза 3: Разрешение через iNaturalist

1. **Оптимизация: пропуск газеттерных кандидатов с полными данными.** Кандидаты,
   найденные газеттером, для которых SQLite-база газеттера уже содержит все поля,
   необходимые для формирования выходной записи (`taxon_id`, `taxon_name`, `taxon_rank`,
   `taxon_common_name`), **пропускают Фазу 3**. Обращение к iNaturalist API для них
   не выполняется — данные берутся напрямую из газеттера.
2. Остальные кандидаты (regex, LLM, газеттерные с неполными данными) отправляются
   в iNaturalist API (endpoint `/v1/taxa/autocomplete`).
3. Результаты кэшируются (in-memory, опционально disk).
4. Для каждого кандидата формируется список matches (до 5 результатов).
5. Определяется значение `identified`
   (см. [критерии](docs/processing.md#критерии-identified)).

### Фаза 4: LLM-обогащение неразрешённых кандидатов

Выполняется только если LLM-обогатитель включён в конфигурации.

1. Кандидаты с пустым `matches` или `identified: "no"` передаются в LLM-обогатитель.
2. LLM получает кандидатное название + контекстное предложение, возвращает альтернативные
   русские и английские названия.
3. Альтернативные названия отправляются в iNaturalist для повторного поиска.
4. Результаты повторного поиска объединяются с существующими matches.

### Фаза 5: Сборка результата

1. Разрешённые данные раскладываются по всем вхождениям: если «липа» встречается 30 раз,
   разрешение выполняется 1 раз, а результат применяется ко всем 30 вхождениям.
2. Результат фильтруется по порогу `confidence` из конфигурации.
3. Формируется итоговый JSON:
   - **По умолчанию (дедуплицированный режим):** одна запись на уникальный таксон
     с полем `count` и массивом `occurrences` (каждое вхождение с `line_number`,
     `source_text`, `source_context`).
   - **С флагом `--all-occurrences`:** одна запись на каждое вхождение (без группировки).

## Прогресс

Обработка книги — длительная операция (минуты–десятки минут). Генератор yield'ит
`PhaseProgress` на каждом значимом шаге:
- Фаза 1: после обработки каждого LLM-чанка.
- Фаза 3: после каждого запроса к iNaturalist API.
- Фаза 4: после каждого запроса к LLM-обогатителю.

CLI использует события для прогресс-бара (`click.progressbar` или аналог).

## Подробная документация

- [Модели данных](docs/models.md) — внутренние структуры, поток данных между фазами,
  события пайплайна, протоколы.
- [Обработка и алгоритмы](docs/processing.md) — экстракторы, нормализация, confidence,
  identified, LLM, чанкинг, дедупликация, кэширование.
- [Форматы данных и CLI](docs/data-and-cli.md) — входные/выходные форматы, конфигурация,
  CLI, ограничения API, обработка ошибок.
